# -*- coding: utf-8 -*-
"""mnist_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f7E7jnZmISIzvLbvhsvjPYubmRw0CLiV
"""

from matplotlib import pyplot
import os
import tensorflow as tf
from tensorflow import keras
import numpy as np
import pathlib
import sys
import logging
logging.getLogger("tensorflow").setLevel(logging.DEBUG)

from google.colab import drive
drive.mount('/content/gdrive')

# load train and test dataset
def load_dataset():
# load dataset
  mnist = keras.datasets.mnist
  (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
	
  return train_images, train_labels, test_images, test_labels

# scale pixels
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm

# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

# define cnn model
def define_model():
  model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  tf.keras.layers.Conv2D(32, (7,7), (2,2), padding='same', use_bias=False, activation='relu'),
  tf.keras.layers.MaxPooling2D((3, 2), padding="same"),
#prwto layer
  tf.keras.layers.Conv2D(64, (7,7), (2,2), padding='same', use_bias=False, activation='relu'),
  tf.keras.layers.MaxPooling2D((3, 2), padding="same"),
#deytero
  tf.keras.layers.Conv2D(64, (3,3), (1,1), padding='same', use_bias=False, activation='relu'),
  tf.keras.layers.MaxPooling2D((3, 2), padding="same"),

#trito
  tf.keras.layers.Conv2D(32,(1,1), strides=(1,1), padding='same', use_bias=False, activation='relu'),
  tf.keras.layers.MaxPooling2D((2, 2), padding="same"),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
  ])
  model.compile(optimizer='adam',
                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])
  return model

# load dataset
train_images, train_labels, test_images, test_labels = load_dataset()
# prepare pixel data
train_images, test_images = prep_pixels(train_images, test_images)
# define model
model = define_model()
# fit model
history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels), verbose=0)
# evaluate model
_, acc = model.evaluate(test_images, test_labels, verbose=0)
print('> %.3f' % (acc * 100.0))
# learning curves
summarize_diagnostics(history)

model.save('/content/gdrive/MyDrive/Διπλωματική Κώδικες τελικοί/saved_models/mnist.h5')
