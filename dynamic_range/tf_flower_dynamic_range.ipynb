{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy7fLXUe6WMJ5wdVe/hasM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanziog/Quantized-Deep-Neural-Networks/blob/main/tf_flower_dynamic_range.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPg_pG6lwiBq"
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
        "import glob\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from matplotlib import pyplot\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import sys\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdiZBSi-70at",
        "outputId": "555dd142-745c-4d49-a54c-3e051e663331"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSgD2sfXxDzM"
      },
      "source": [
        "def load_dataset():\n",
        "# load dataset\n",
        "  dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "  data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "  data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "  image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "  print(image_count)\n",
        "  roses = list(data_dir.glob('roses/*'))\n",
        "  PIL.Image.open(str(roses[0]))\n",
        "\n",
        "  categories = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "\n",
        "\n",
        "  daisy = list(data_dir.glob('daisy/*'))\n",
        "  dandelion = list(data_dir.glob('dandelion/*'))\n",
        "  roses = list(data_dir.glob('roses/*'))\n",
        "  sunflowers = list(data_dir.glob('sunflowers/*'))\n",
        "  tulips = list(data_dir.glob('turlips/*'))\n",
        "\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  for i in daisy:\n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',\n",
        "    target_size =  (280,280))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(0)\n",
        "  for i in dandelion:\n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',\n",
        "    target_size= (280,280))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(1)\n",
        "  for i in roses:\n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',\n",
        "    target_size= (280,280))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(2)\n",
        "  for i in sunflowers:\n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',\n",
        "    target_size= (280,280))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(3)\n",
        "  for i in tulips:\n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',\n",
        "    target_size= (280,280))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(3)\n",
        "  data = np.array(data)\n",
        "  labels = np.array(labels)\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=0.2,\n",
        "                                                random_state=42)\n",
        "\t\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0n6VNeyxkKT"
      },
      "source": [
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAqUCDtnx_LW"
      },
      "source": [
        "#FOR THE QNN MODEL\n",
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNQczvdwyKjH",
        "outputId": "84f05b18-9213-4a81-afd9-7a5faff9fcf8"
      },
      "source": [
        "# load dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "train_images, test_images = prep_pixels(train_images, test_images)\n",
        "\n",
        "#load model\n",
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/Διπλωματική Κώδικες τελικοί/saved_models/tf_flower.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 3s 0us/step\n",
            "228827136/228813984 [==============================] - 3s 0us/step\n",
            "3670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPsYIlHz0Jf",
        "outputId": "6e3942aa-c0a8-4f18-bc85-218d71cb9409"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp55a4qk3f/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka3pUqHpz7hE"
      },
      "source": [
        "tflite_models_dir = pathlib.Path(\"/tmp/flower_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqLGNp9gz861",
        "outputId": "a1603f89-f046-4e4a-b1a8-5b9d6d3d59f4"
      },
      "source": [
        "tflite_model_file = tflite_models_dir/\"flower_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10771216"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi1dezkrz_y3",
        "outputId": "3703a783-5af2-47c7-c102-1418796f1c47"
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"flower_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_quant_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpij_vrk6t/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpij_vrk6t/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2714912"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWxQWjnj0C_v",
        "outputId": "f1846953-9c34-4041-b0c0-5fd3bf51c7fe"
      },
      "source": [
        "ls -lh {tflite_models_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 13M\n",
            "-rw-r--r-- 1 root root 2.6M Sep 17 08:38 flower_model_quant.tflite\n",
            "-rw-r--r-- 1 root root  11M Sep 17 08:38 flower_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXT72gRc0E_H"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwugbWd_0Ha8"
      },
      "source": [
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGY6iTv00JUg"
      },
      "source": [
        "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "interpreter.set_tensor(input_index, test_image)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(output_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyXhe55i0O03",
        "outputId": "df89b088-7fd7-4a77-8e7b-b6419cab1d6e"
      },
      "source": [
        "print(evaluate_model(interpreter))\n",
        "print(evaluate_model(interpreter_quant))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.768695652173913\n",
            "0.7669565217391304\n"
          ]
        }
      ]
    }
  ]
}
