{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL3mcKNG3qbJoNlaXyymLB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanziog/Quantized-Deep-Neural-Networks/blob/main/mnist_float16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1boHSdm7KT",
        "outputId": "2dc8be99-6e4b-497a-d8e2-f3a7912ac519"
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "tf.float16\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0EIfh-nCz4"
      },
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "# load dataset\n",
        "  mnist = keras.datasets.mnist\n",
        "  (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\t\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZe3omgonJ73"
      },
      "source": [
        "#EVALUATE MODEL\n",
        "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for test_image in test_images:\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  accurate_count = 0\n",
        "  for index in range(len(prediction_digits)):\n",
        "    if prediction_digits[index] == test_labels[index]:\n",
        "      accurate_count += 1\n",
        "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpEGbU5fnKih",
        "outputId": "03974959-a182-410f-fa0a-ed2246ff7bdd"
      },
      "source": [
        "# load dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "\n",
        "# prepare pixel data\n",
        "train_images, test_images = prep_pixels(train_images, test_images)\n",
        "\n",
        "#load model\n",
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/Διπλωματική Κώδικες τελικοί/saved_models/mnist.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9XfcEZCnPLY",
        "outputId": "4a248c15-91f1-4549-c135-1bfcfc0cfebe"
      },
      "source": [
        "# Convert to a Tensorflow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt0nz4hct/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9lDwpQsnVEB"
      },
      "source": [
        "tflite_models_dir = pathlib.Path(\"/tmp/mnist_f16_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJPLt1D7nXdf",
        "outputId": "975bb8e3-a1de-443f-9bce-12918b77b0de"
      },
      "source": [
        "tflite_model_file = tflite_models_dir/\"mnist_f16_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569300"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwTcBFannZI8"
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-5dDfVRnbRP",
        "outputId": "9fbc7ca4-58f5-4a42-9a47-caec580f3ebc"
      },
      "source": [
        "tflite_fp16_model = converter.convert()\n",
        "tflite_model_fp16_file = tflite_models_dir/\"mnist_f16_model_quant_f16.tflite\"\n",
        "tflite_model_fp16_file.write_bytes(tflite_fp16_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8um2gba4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8um2gba4/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "288080"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ol7ii7nfAb"
      },
      "source": [
        "#LOAD LITE MODEL\n",
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNiPkDRQnfy3"
      },
      "source": [
        "interpreter_fp16 = tf.lite.Interpreter(model_path=str(tflite_model_fp16_file))\n",
        "interpreter_fp16.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pStjCM5anhf9"
      },
      "source": [
        "#TEST LITE MODEL ON IMAGE\n",
        "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "interpreter.set_tensor(input_index, test_image)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(output_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "0fmBC6aanjcN",
        "outputId": "2aeee374-92ac-4eff-9eea-31b4f03b48f0"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "plt.imshow(test_images[0])\n",
        "template = \"True:{true}, predicted:{predict}\"\n",
        "_ = plt.title(template.format(true= str(test_labels[0]),\n",
        "                              predict=str(np.argmax(predictions[0]))))\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soaaNkqynlct"
      },
      "source": [
        "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
        "\n",
        "input_index = interpreter_fp16.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter_fp16.get_output_details()[0][\"index\"]\n",
        "\n",
        "interpreter_fp16.set_tensor(input_index, test_image)\n",
        "interpreter_fp16.invoke()\n",
        "predictions = interpreter_fp16.get_tensor(output_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q2cPKkunnu1",
        "outputId": "8f25d125-9f76-4697-e3ad-5fa2579da310"
      },
      "source": [
        "print(evaluate_model(interpreter))\n",
        "# NOTE: Colab runs on server CPUs. At the time of writing this, TensorFlow Lite\n",
        "# doesn't have super optimized server CPU kernels. For this reason this may be\n",
        "# slower than the above float interpreter. But for mobile CPUs, considerable\n",
        "# speedup can be observed.\n",
        "print(evaluate_model(interpreter_fp16))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9866\n",
            "0.9866\n"
          ]
        }
      ]
    }
  ]
}
